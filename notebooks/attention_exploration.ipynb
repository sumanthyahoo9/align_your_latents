{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd558e5",
   "metadata": {},
   "source": [
    "##### Use this notebook to understand how the Attention layers work in the video generation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a261743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Attention\n",
    "# Spatial attention is where, we have apply the attention map \n",
    "# across the height and width dimensions\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatial Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, num_heads:int = 8):\n",
    "        super().__init__()\n",
    "        assert channels%num_heads == 0\n",
    "        self.mha = nn.MultiheadAttention(\n",
    "            embed_dim=channels,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        x: (B, C, H, W)\n",
    "        \"\"\"\n",
    "        _, _, H, W = x.shape\n",
    "        # Reshape to (B, H*W, C)\n",
    "        print(f\"\\n The inputs are of shape \\n {x.shape}\")\n",
    "        x = rearrange(x, \"b c h w -> b (h w) c\")\n",
    "        print(f\"\\n The inputs to the attention are \\n {x.shape}\")\n",
    "        # Apply attention\n",
    "        x, x_attn_weights = self.mha(x, x, x)\n",
    "        print(f\"\\n The output of the attention network is \\n {x.shape}\")\n",
    "        print(f\"\\n The attention weights are of shape \\n {x_attn_weights.shape}\")\n",
    "        x = rearrange(x, \"b (h w) c -> b c h w\", h=H, w=W)\n",
    "        print(f\"\\n The final shape after Spatial attention is \\n {x.shape}\")\n",
    "        return x\n",
    "\n",
    "# Test the spatial attention code\n",
    "B, C, H, W = 16, 512, 32, 32\n",
    "x = torch.randn(B, C, H, W)\n",
    "spatial_attn = SpatialAttention(C)\n",
    "out = spatial_attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb538c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Module for temporal attention\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, num_heads: int = 8):\n",
    "        \"\"\"\n",
    "        Temporal self-attention over T dimension\n",
    "        Input: (B, C, T, H, W)\n",
    "        Output: (B, C, T, H, W)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(\n",
    "            embed_dim=channels,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        x: (B, C, T, H, W)\n",
    "        \"\"\"\n",
    "        B, _, _, H, _ = x.shape\n",
    "        print(f\"\\n The shape of the inputs going into the temporal attention module is \\n {x.shape}\")\n",
    "        # Reshape to (B*H*W, T, C)\n",
    "        x = rearrange(x, \"b c t h w -> (b h w) t c\")\n",
    "        print(f\"\\n Prior to actual application of the attention mechanism, the shape of the inputs is \\n {x.shape}\")\n",
    "        # Apply attention\n",
    "        x, x_attn_weights = self.mha(x, x, x)\n",
    "        # Reshape back to (B, C, T, H, W)\n",
    "        print(f\"\\n Right after the attention mechanism, the outputs are of shape \\n {x.shape}\")\n",
    "        print(f\"\\n The attention weights are of shape \\n {x_attn_weights.shape}\")\n",
    "        x = rearrange(x, \"(b h w) t c -> b c t h w\", b=B, h=H)\n",
    "        print(f\"\\n The outputs are reshaped to \\n {x.shape}\")\n",
    "        return x\n",
    "B, C, T, H, W = 2, 512, 16, 32, 32\n",
    "x = torch.randint(0, 256, (B, C, T, H, W)).float()\n",
    "temp_attention_module = TemporalAttention(C)\n",
    "x_temp = temp_attention_module(x)\n",
    "assert x_temp.shape == (B, C, T, H, W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm_video_env (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
