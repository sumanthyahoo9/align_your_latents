{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ca45e7",
   "metadata": {},
   "source": [
    "##### Use this notebook to understand the U-net blocks and the U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb91f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Self-attention\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, num_heads:int =8):\n",
    "        super().__init__()\n",
    "        assert channels%num_heads == 0\n",
    "        self.mha = nn.MultiheadAttention(\n",
    "            embed_dim=channels,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        x: (B, C, H, W)\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "        # Reshape to (B, H*W, C)\n",
    "        x = rearrange(x, \"b c h w -> b (h w) c\")\n",
    "        # Apply attention\n",
    "        x, _ = self.mha(x, x, x)\n",
    "        # Reshape back to (B, C, H, W)\n",
    "        x = rearrange(x, \"b (h w) c -> b c h w\", h=H, w=W)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ONE down-block\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        time_emb_dim: int = 1280,\n",
    "        num_groups: int = 32,\n",
    "        use_attention: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First conv block\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(num_groups, out_channels)\n",
    "        \n",
    "        # Time embedding projection\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_channels)\n",
    "        \n",
    "        # Second conv block\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(num_groups, out_channels)\n",
    "        \n",
    "        # Residual connection (if channels change)\n",
    "        self.residual_conv = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        \n",
    "        # Optional attention\n",
    "        self.attention = SpatialAttention(out_channels) if use_attention else nn.Identity()\n",
    "        \n",
    "        # Downsample\n",
    "        self.downsample = nn.Conv2d(out_channels, out_channels, 3, stride=2, padding=1)\n",
    "        \n",
    "        self.silu = nn.SiLU()\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        print(f\"The shape of the residual is {residual.shape} and that of the input is {x.shape}\")\n",
    "        # First conv block\n",
    "        x = self.conv1(x)\n",
    "        print(f\"\\n After first convolution, the shape of the inputs is \\n {x.shape}\")\n",
    "        x = self.norm1(x)\n",
    "        print(f\"\\n After first group norm, the shape of the inputs is \\n {x.shape}\")\n",
    "        x = self.silu(x)\n",
    "        print(f\"\\n After first activation, the shape of the inputs is \\n {x.shape}\")\n",
    "        \n",
    "        # Add time embedding (broadcast over spatial dims)\n",
    "        t = self.time_mlp(t_emb)\n",
    "        #assert t.shape == t_emb.shape\n",
    "        print(f\"\\n The time embeddings are of originally shape \\n {t_emb.shape}\")\n",
    "        t = t[:, :, None, None]  # (B, C, 1, 1)\n",
    "        print(f\"\\n The time embeddings are reshaped through broadcasting to \\n {t.shape}\")\n",
    "        x = x + t\n",
    "        print(f\"\\n The inputs are concatenated with the time embeddings to give \\n {x.shape}\")\n",
    "        \n",
    "        # Second conv block\n",
    "        x = self.conv2(x)\n",
    "        print(f\"\\n After the second convolution, the shape of the inputs is \\n {x.shape}\")\n",
    "        x = self.norm2(x)\n",
    "        print(f\"\\n After the second group norm, the shape of the inputs is \\n {x.shape}\")\n",
    "        \n",
    "        # Residual connection\n",
    "        print(f\"The shape of the residual is {residual.shape}\")\n",
    "        residual = self.residual_conv(residual)\n",
    "        print(f\"\\n After the residual convolution, the shape of the residual is \\n {residual.shape}\")\n",
    "        x = x + residual\n",
    "        print(f\"After adding the residual, the shape of the input is {x.shape}\")\n",
    "        x = self.silu(x)\n",
    "        print(f\"After the final activation, the shape of the inputs is {x.shape}\")\n",
    "        \n",
    "        # Optional attention\n",
    "        x = self.attention(x)\n",
    "        print(f\"After attention, the shape is {x.shape}\")\n",
    "        \n",
    "        # Downsample\n",
    "        x = self.downsample(x)\n",
    "        print(f\"After downsampling, the shape of the inputs is {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, C, H, W = 2, 16, 32, 32\n",
    "x = torch.randn(B, C, H, W)\n",
    "t_emb_dim = 1280\n",
    "down_block = DownBlock(in_channels=16,\n",
    "                        out_channels=32)\n",
    "t_emb = torch.randn(B, t_emb_dim)\n",
    "out = down_block(x, t_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Upsampling block for U-Net decoder\n",
    "    Input: (B, in_channels, H, W) + skip (B, skip_channels, H*2, W*2)\n",
    "    Output: (B, out_channels, H*2, W*2)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        skip_channels: int,\n",
    "        time_emb_dim: int = 1280,\n",
    "        num_groups: int = 32,\n",
    "        use_attention: bool = False,\n",
    "        do_upsample: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.do_upsample = do_upsample\n",
    "        \n",
    "        # After concat with skip: in_channels + skip_channels\n",
    "        total_channels = in_channels + skip_channels\n",
    "        \n",
    "        # First conv block\n",
    "        self.conv1 = nn.Conv2d(total_channels, out_channels, 3, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(num_groups, out_channels)\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_channels)\n",
    "        \n",
    "        # Second conv block\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(num_groups, out_channels)\n",
    "        \n",
    "        # Residual\n",
    "        self.residual_conv = nn.Conv2d(total_channels, out_channels, 1)\n",
    "        \n",
    "        # Optional attention\n",
    "        self.attention = SpatialAttention(out_channels) if use_attention else nn.Identity()\n",
    "        \n",
    "        # Upsample LAST - operates on out_channels!\n",
    "        self.upsample = nn.ConvTranspose2d(out_channels, out_channels, 4, stride=2, padding=1)  # ← FIX!\n",
    "        \n",
    "        self.silu = nn.SiLU()\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        skip: torch.Tensor, \n",
    "        t_emb: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B, in_channels, H, W)\n",
    "        skip: (B, skip_channels, H*2, W*2) from encoder\n",
    "        t_emb: (B, time_emb_dim)\n",
    "        \"\"\"\n",
    "        print(f\"The inputs are of shape \\n {x.shape}\")\n",
    "        print(f\"\\n The skip connections are of shape \\n {skip.shape}\")\n",
    "        print(f\"\\n The time embedding is of shape {t_emb.shape}\")\n",
    "        # Concatenate with skip\n",
    "        x = torch.cat([x, skip], dim=1)  # (B, in_channels+skip_channels, H*2, W*2)\n",
    "        print(f\"\\n The concatenated input (input + skip) is of shape \\n {x.shape}\")\n",
    "        \n",
    "        # Save for residual\n",
    "        residual = x\n",
    "        \n",
    "        # First conv\n",
    "        x = self.conv1(x)\n",
    "        print(f\"\\n After first convolution, the shape of the inputs is \\n {x.shape}\")\n",
    "        x = self.norm1(x)\n",
    "        print(f\"\\n After first group norm, the shape of the inputs is \\n {x.shape}\")\n",
    "        x = self.silu(x)\n",
    "        print(f\"\\n After first silu activation, the shape of the inputs is \\n {x.shape}\")\n",
    "        \n",
    "        # Time embedding\n",
    "        t = self.time_mlp(t_emb)[:, :, None, None]\n",
    "        print(f\"\\n The time embeddings are reshaped to \\n {t.shape}\")\n",
    "        x = x + t\n",
    "        print(f\"\\n After adding the time embeddings/position info, the shape is \\n {x.shape}\")\n",
    "        \n",
    "        # Second conv\n",
    "        x = self.conv2(x)\n",
    "        print(f\"\\n After second convolution, the shape of the inputs is \\n {x.shape}\")\n",
    "        x = self.norm2(x)\n",
    "        print(f\"\\n After second group norm, the shape of the inputs is \\n {x.shape}\")\n",
    "\n",
    "        # Residual\n",
    "        residual = self.residual_conv(residual)\n",
    "        print(f\"\\n The residual shape is \\n {residual.shape}\")\n",
    "        x = x + residual\n",
    "        print(f\"\\n After adding the residual, the shape of the inputs is \\n {x.shape}\")\n",
    "        x = self.silu(x)\n",
    "        print(f\"\\n After the second silu activation, the shape of the inputs is \\n {x.shape}\")\n",
    "        \n",
    "        # Attention\n",
    "        x = self.attention(x)\n",
    "        print(f\"\\n After attention, the shape of the inputs is \\n {x.shape}\")\n",
    "        # Upsample\n",
    "        if self.do_upsample:\n",
    "            x = self.upsample(x)  # (B, in_channels, H*2, W*2)\n",
    "        print(f\"\\n After the upsampling, the shape of the inputs is \\n {x.shape}\")\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Up-convolution block\n",
    "B, in_ch, out_ch, skip_ch = 2, 64, 128, 32\n",
    "H, W = 16, 16\n",
    "\n",
    "x = torch.randn(B, in_ch, H, W)\n",
    "skip = torch.randn(B, skip_ch, H, W)  # ← SAME size as x!\n",
    "t_emb = torch.randn(B, 1280)\n",
    "\n",
    "up_block = UpBlock(in_ch, out_ch, skip_ch)\n",
    "out = up_block(x, skip, t_emb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm_video_env (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
